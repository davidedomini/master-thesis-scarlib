@article{abowd2016beyond,
  title={Beyond weiser: From ubiquitous to collective computing},
  author={Abowd, Gregory D},
  journal={Computer},
  volume={49},
  number={1},
  pages={17--23},
  year={2016},
  publisher={IEEE}
}

@article{schranz2021swarm,
  title={Swarm intelligence and cyber-physical systems: concepts, challenges and future trends},
  author={Schranz, Melanie and Di Caro, Gianni A and Schmickl, Thomas and Elmenreich, Wilfried and Arvin, Farshad and {\c{S}}ekercio{\u{g}}lu, Ahmet and Sende, Micha},
  journal={Swarm and Evolutionary Computation},
  volume={60},
  pages={100762},
  year={2021},
  publisher={Elsevier}
}

@incollection{tumer2004survey,
  title={A survey of collectives},
  author={Tumer, Kagan and Wolpert, David},
  booktitle={Collectives and the design of complex systems},
  pages={1--42},
  year={2004},
  publisher={Springer}
}

@inproceedings{schmeck2011organic,
  title={Organic Computing--A Generic Approach to Controlled Self-organization in Adaptive Systems},
  author={Schmeck, Hartmut},
  booktitle={Multiagent System Technologies: 9th German Conference, MATES 2011, Berlin, Germany, October 6-7, 2011. Proceedings 9},
  pages={2--2},
  year={2011},
  organization={Springer}
}

@article{dorri2018multi,
  title={Multi-agent systems: A survey},
  author={Dorri, Ali and Kanhere, Salil S and Jurdak, Raja},
  journal={Ieee Access},
  volume={6},
  pages={28573--28593},
  year={2018},
  publisher={IEEE}
}

@article{yang2022overview,
  title={An overview of recent advances in distributed coordination of multi-agent systems},
  author={Yang, Ruohan and Liu, Lu and Feng, Gang},
  journal={Unmanned Systems},
  volume={10},
  number={03},
  pages={307--325},
  year={2022},
  publisher={World Scientific}
}

@book{bond2014readings,
  title={Readings in distributed artificial intelligence},
  author={Bond, Alan H and Gasser, Les},
  year={2014},
  publisher={Morgan Kaufmann}
}

@article{zedadra2019swarm,
  title={Swarm intelligence and IoT-based smart cities: a review},
  author={Zedadra, Ouarda and Guerrieri, Antonio and Jouandeau, Nicolas and Spezzano, Giandomenico and Seridi, Hamid and Fortino, Giancarlo},
  journal={The internet of things for smart urban ecosystems},
  pages={177--200},
  year={2019},
  publisher={Springer}
}

@article{brambilla2013swarm,
  title={Swarm robotics: a review from the swarm engineering perspective},
  author={Brambilla, Manuele and Ferrante, Eliseo and Birattari, Mauro and Dorigo, Marco},
  journal={Swarm Intelligence},
  volume={7},
  pages={1--41},
  year={2013},
  publisher={Springer}
}

@article{uslu2023role,
  title={The role of MAS interoperability for IoT applications: A survey on recent advances in manufacturing systems},
  author={Uslu, Banu Calis and Agent, Multi-Agent},
  journal={Journal of the Faculty of Engineering and Architecture of Gazi University},
  volume={38},
  number={2},
  pages={1279--1297},
  year={2023},
  publisher={GAZI UNIV, FAC ENGINEERING ARCHITECTURE BAYAR BULVARI, MALTEPE, ANKARA~…}
}

@inproceedings{viroli2018field,
  title={From field-based coordination to aggregate computing},
  author={Viroli, Mirko and Beal, Jacob and Damiani, Ferruccio and Audrito, Giorgio and Casadei, Roberto and Pianini, Danilo},
  booktitle={Coordination Models and Languages: 20th IFIP WG 6.1 International Conference, COORDINATION 2018, Held as Part of the 13th International Federated Conference on Distributed Computing Techniques, DisCoTec 2018, Madrid, Spain, June 18-21, 2018. Proceedings 20},
  pages={252--279},
  year={2018},
  organization={Springer}
}

@article{busoniu2008comprehensive,
  title={A comprehensive survey of multiagent reinforcement learning},
  author={Busoniu, Lucian and Babuska, Robert and De Schutter, Bart},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume={38},
  number={2},
  pages={156--172},
  year={2008},
  publisher={IEEE}
}

@article{wu2020comprehensive,
  title={A comprehensive survey on graph neural networks},
  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Philip, S Yu},
  journal={IEEE transactions on neural networks and learning systems},
  volume={32},
  number={1},
  pages={4--24},
  year={2020},
  publisher={IEEE}
}

@article{hernandez2017survey,
  title={A survey of learning in multiagent environments: Dealing with non-stationarity},
  author={Hernandez-Leal, Pablo and Kaisers, Michael and Baarslag, Tim and De Cote, Enrique Munoz},
  journal={arXiv preprint arXiv:1707.09183},
  year={2017}
}

@InProceedings{scarlib,
author={Domini, Davide
and Cavallari, Filippo
and Aguzzi, Gianluca
and Viroli, Mirko},
editor={Jongmans, Sung-Shik
and Lopes, Ant{\'o}nia},
title={ScaRLib: A Framework for Cooperative Many Agent Deep Reinforcement Learning in Scala},
booktitle={Coordination Models and Languages},
year={2023},
publisher={Springer Nature Switzerland},
address={Cham},
pages={52-70},
abstract={Multi Agent Reinforcement Learning (MARL) is an emerging field in machine learning where multiple agents learn, simultaneously and in a shared environment, how to optimise a global or local reward signal. MARL has gained significant interest in recent years due to its successful applications in various domains, such as robotics, IoT, and traffic control. Cooperative Many Agent Reinforcement Learning (CMARL) is a relevant subclass of MARL, where thousands of agents work together to achieve a common coordination goal.},
isbn={978-3-031-35361-1}
}

@article{casadei2022scafi,
  title={Scafi: A scala DSL and toolkit for aggregate programming},
  author={Casadei, Roberto and Viroli, Mirko and Aguzzi, Gianluca and Pianini, Danilo},
  journal={SoftwareX},
  volume={20},
  pages={101248},
  year={2022},
  publisher={Elsevier}
}

@article{pianini2013chemical,
  title={Chemical-oriented simulation of computational systems with ALCHEMIST},
  author={Pianini, Danilo and Montagna, Sara and Viroli, Mirko},
  journal={Journal of Simulation},
  volume={7},
  number={3},
  pages={202--215},
  year={2013},
  publisher={Springer}
}

@article{RLSurvey,
author = {Kaelbling, Leslie Pack and Littman, Michael L. and Moore, Andrew W.},
title = {Reinforcement Learning: A Survey},
year = {1996},
issue_date = {Jnauary 1996},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {4},
number = {1},
issn = {1076-9757},
abstract = {This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word "reinforcement." The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.},
journal = {J. Artif. Int. Res.},
month = {may},
pages = {237–285},
numpages = {49}
}

@misc{dqn,
  doi = {10.48550/ARXIV.1312.5602},
  url = {https://arxiv.org/abs/1312.5602},
  author = {Mnih,  Volodymyr and Kavukcuoglu,  Koray and Silver,  David and Graves,  Alex and Antonoglou,  Ioannis and Wierstra,  Daan and Riedmiller,  Martin},
  keywords = {Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Playing Atari with Deep Reinforcement Learning},
  publisher = {arXiv},
  year = {2013},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@article{QL,
  doi = {10.1007/bf00992698},
  url = {https://doi.org/10.1007/bf00992698},
  year = {1992},
  month = may,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {8},
  number = {3-4},
  pages = {279--292},
  author = {Christopher J. C. H. Watkins and Peter Dayan},
  title = {Q-learning},
  journal = {Machine Learning}
}

@misc{ppo,
      title={Proximal Policy Optimization Algorithms}, 
      author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
      year={2017},
      eprint={1707.06347},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@incollection{LITTMAN1994157,
title = {Markov games as a framework for multi-agent reinforcement learning},
editor = {William W. Cohen and Haym Hirsh},
booktitle = {Machine Learning Proceedings 1994},
publisher = {Morgan Kaufmann},
address = {San Francisco (CA)},
pages = {157-163},
year = {1994},
isbn = {978-1-55860-335-6},
doi = {https://doi.org/10.1016/B978-1-55860-335-6.50027-1},
url = {https://www.sciencedirect.com/science/article/pii/B9781558603356500271},
author = {Michael L. Littman},
abstract = {In the Markov decision process (MDP) formalization of reinforcement learning, a single adaptive agent interacts with an environment defined by a probabilistic transition function. In this solipsis-tic view, secondary agents can only be part of the environment and are therefore fixed in their behavior. The framework of Markov games allows us to widen this view to include multiple adaptive agents with interacting or competing goals. This paper considers a step in this direction in which exactly two agents with diametrically opposed goals share an environment. It describes a Q-learning-like algorithm for finding optimal policies and demonstrates its application to a simple two-player game in which the optimal policy is probabilistic.}
}

@phdthesis{yang2021many,
  title={Many-agent Reinforcement Learning},
  author={Yang, Yaodong},
  year={2021},
  school={UCL (University College London)}
}

@misc{smac,
  doi = {10.48550/ARXIV.1902.04043},
  url = {https://arxiv.org/abs/1902.04043},
  author = {Samvelyan,  Mikayel and Rashid,  Tabish and de Witt,  Christian Schroeder and Farquhar,  Gregory and Nardelli,  Nantas and Rudner,  Tim G. J. and Hung,  Chia-Man and Torr,  Philip H. S. and Foerster,  Jakob and Whiteson,  Shimon},
  keywords = {Machine Learning (cs.LG),  Multiagent Systems (cs.MA),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {The StarCraft Multi-Agent Challenge},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{marl-curricula,
  doi = {10.48550/ARXIV.1909.07528},
  url = {https://arxiv.org/abs/1909.07528},
  author = {Baker,  Bowen and Kanitscheider,  Ingmar and Markov,  Todor and Wu,  Yi and Powell,  Glenn and McGrew,  Bob and Mordatch,  Igor},
  keywords = {Machine Learning (cs.LG),  Artificial Intelligence (cs.AI),  Multiagent Systems (cs.MA),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Emergent Tool Use From Multi-Agent Autocurricula},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}